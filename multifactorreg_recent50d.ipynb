{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb18558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# --------------- config ---------------\n",
    "INPUT_XLSX = \"Project.xlsx\"\n",
    "OUTPUT_DIR = Path(\"output_datasets\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7740ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- helpers ---------------\n",
    "def _parse_date(s):\n",
    "    \"\"\"Parse dates as day-first (matches screenshots).\"\"\"\n",
    "    return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "def _norm_cols(df):\n",
    "    \"\"\"Trim and collapse whitespace in headers.\"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        pd.Index(df.columns)\n",
    "        .map(lambda c: \"\" if pd.isna(c) else str(c))\n",
    "        .map(lambda c: c.strip())\n",
    "        .map(lambda c: re.sub(r\"\\s+\", \" \", c))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def _pick_column_for_code(code, mapping_dict):\n",
    "    \"\"\"Return best matching column for a portfolio code from a dict {code: colname}.\"\"\"\n",
    "    if code in mapping_dict:\n",
    "        return mapping_dict[code]\n",
    "    # Fallback: trailing/leading digit overlaps\n",
    "    for k, v in mapping_dict.items():\n",
    "        if not k:\n",
    "            continue\n",
    "        if code.endswith(k) or k.endswith(code):\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "def _require_columns(df, needed, context):\n",
    "    \"\"\"Raise early if required columns are missing.\"\"\"\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"[{context}] Missing expected columns: {missing}\")\n",
    "\n",
    "def ensure_date_column(df, preferred=(\"Date\", \"Dates\", \"Row Labels\")):\n",
    "    \"\"\"\n",
    "    Guarantee a 'Date' column:\n",
    "      1) Try common labels (case-insensitive).\n",
    "      2) Else promote the first column to 'Date'.\n",
    "    Then parse dates day-first.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = [(\"\" if pd.isna(c) else str(c)).strip() for c in df.columns]\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    for p in preferred:\n",
    "        p_l = p.lower()\n",
    "        if p_l in lower:\n",
    "            if lower[p_l] != \"Date\":\n",
    "                df = df.rename(columns={lower[p_l]: \"Date\"})\n",
    "            break\n",
    "    else:\n",
    "        first_col = df.columns[0]\n",
    "        if first_col != \"Date\":\n",
    "            df = df.rename(columns={first_col: \"Date\"})\n",
    "    df[\"Date\"] = _parse_date(df[\"Date\"])\n",
    "    return df\n",
    "\n",
    "# ---------- Curve helpers (kept; not used after the change) ----------\n",
    "def find_20y_column(curve_df):\n",
    "    \"\"\"\n",
    "    Find the 20Y tenor column:\n",
    "      - Prefer exact numeric header '20' / '20.0'.\n",
    "      - Fallback to textual variants (20YR / 20 YEAR / 20Y).\n",
    "    \"\"\"\n",
    "    for c in curve_df.columns:\n",
    "        try:\n",
    "            if abs(float(str(c).strip()) - 20.0) < 1e-12:\n",
    "                return c\n",
    "        except Exception:\n",
    "            continue\n",
    "    rx_list = [r\"^\\s*20\\s*$\", r\"^\\s*20\\.0+\\s*$\", r\".*\\b20\\s*YR\\b.*\", r\".*\\b20\\s*YEAR\\b.*\", r\".*\\b20Y\\b.*\"]\n",
    "    for c in curve_df.columns:\n",
    "        if any(re.search(rx, str(c), flags=re.IGNORECASE) for rx in rx_list):\n",
    "            return c\n",
    "    raise ValueError(\"[Curve] Could not locate a 20-year tenor column (header like 20 / 20.0).\")\n",
    "\n",
    "def find_spread_col(curve_df, which=\"A\"):\n",
    "    \"\"\"\n",
    "    Find Spread A / Spread BBB columns. Accepts 'A'/'BBB' or 'Spread A'/'Spread BBB'.\n",
    "    \"\"\"\n",
    "    patterns = {\n",
    "        \"A\":   [r\"^\\s*A\\s*$\", r\".*\\bSpread\\s*A\\b.*\"],\n",
    "        \"BBB\": [r\"^\\s*BBB\\s*$\", r\".*\\bSpread\\s*B{3}\\b.*\"],\n",
    "    }[which]\n",
    "    matches = []\n",
    "    for c in curve_df.columns:\n",
    "        if any(re.search(rx, str(c), flags=re.IGNORECASE) for rx in patterns):\n",
    "            matches.append(c)\n",
    "    if not matches:\n",
    "        raise ValueError(f\"[Curve] Could not find a column for Spread {which} (try 'A' or 'Spread A').\")\n",
    "    return max(matches, key=lambda s: len(str(s)))  # prefer most explicit header\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fbb591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- load all sheets ---------------\n",
    "with pd.ExcelFile(INPUT_XLSX) as xls:\n",
    "    portfolios = pd.read_excel(xls, sheet_name=\"Portfolios\")\n",
    "    peergroups = pd.read_excel(xls, sheet_name=\"PeerGroups\")\n",
    "    mapping    = pd.read_excel(xls, sheet_name=\"Portfolio_peerGroup_mapping\")\n",
    "    # Two-row header: row 1 = metric (Muni_OAD/Muni_DTS/YTW), row 2 = code+suffix (e.g., 4316POSONLY)\n",
    "    oad_dts    = pd.read_excel(xls, sheet_name=\"OAD_DTS_YTW\", header=[0, 1])\n",
    "    # curve      = pd.read_excel(xls, sheet_name=\"Curve\")\n",
    "    curve      = pd.read_excel(xls, sheet_name=\"Curve\", header=[0, 1])\n",
    "    housing    = pd.read_excel(xls, sheet_name=\"Housing_spreads\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4315f6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,\n",
       " [Timestamp('2023-01-02 00:00:00'),\n",
       "  Timestamp('2023-01-16 00:00:00'),\n",
       "  Timestamp('2023-02-20 00:00:00'),\n",
       "  Timestamp('2023-04-07 00:00:00'),\n",
       "  Timestamp('2023-05-29 00:00:00')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Holidays: read once and build a normalized date set ----\n",
    "def _read_holidays(path=\"Input_file.xlsx\", sheet=\"Holidays\"):\n",
    "    df = pd.read_excel(path, sheet_name=sheet)\n",
    "    # normalize headers a bit\n",
    "    df.columns = [(\"\" if pd.isna(c) else str(c)).strip() for c in df.columns]\n",
    "    # find the 'Date' column case-insensitively\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    if \"date\" not in lower:\n",
    "        raise ValueError(\"[Holidays] Could not find a 'Date' column in the Holidays sheet.\")\n",
    "    dcol = lower[\"date\"]\n",
    "    # parse as day-first; normalize to midnight\n",
    "    d = pd.to_datetime(df[dcol], dayfirst=True, errors=\"coerce\").dropna().dt.normalize()\n",
    "    return set(d.unique())\n",
    "\n",
    "HOLIDAYS = _read_holidays(\"Input_file.xlsx\", \"Holidays\")\n",
    "len(HOLIDAYS), list(sorted(HOLIDAYS))[:5]  # quick sanity peek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbeaf650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_holidays(df, date_col=\"Date\"):\n",
    "    \"\"\"\n",
    "    Return df with rows removed where Date (normalized) is in HOLIDAYS.\n",
    "    Safe if column is not present.\n",
    "    \"\"\"\n",
    "    if date_col not in df.columns:\n",
    "        return df\n",
    "    out = df.copy()\n",
    "    # parse/normalize without changing your original dtype flow\n",
    "    tmp = pd.to_datetime(out[date_col], dayfirst=True, errors=\"coerce\").dt.normalize()\n",
    "    mask = ~tmp.isin(HOLIDAYS)\n",
    "    return out.loc[mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164dd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios = _drop_holidays(portfolios, \"Date\")\n",
    "peergroups = _drop_holidays(peergroups, \"Date\")\n",
    "oad_dts    = _drop_holidays(oad_dts,    \"Date\")\n",
    "curve      = _drop_holidays(curve,      \"Date\")\n",
    "housing    = _drop_holidays(housing,    \"Date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f534241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------- normalize & prune ---------------\n",
    "portfolios = _norm_cols(portfolios)\n",
    "peergroups = _norm_cols(peergroups)\n",
    "mapping    = _norm_cols(mapping)\n",
    "# oad_dts    = _norm_cols(oad_dts)\n",
    "# curve      = _norm_cols(curve)\n",
    "housing    = _norm_cols(housing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d1c43f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Portfolio_code</th>\n",
       "      <th>Morningstar_name</th>\n",
       "      <th>PeerGroup_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4316</td>\n",
       "      <td>Franklin Federal Tax Free Income Adv</td>\n",
       "      <td>US OE Muni National Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26176</td>\n",
       "      <td>Franklin Municipal Green Bond ETF</td>\n",
       "      <td>US OE Muni National Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4174</td>\n",
       "      <td>Franklin Federal Interm-Term T/F Inc Adv</td>\n",
       "      <td>US OE Muni National Interm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4363</td>\n",
       "      <td>Franklin VA Tax Free Income Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4360</td>\n",
       "      <td>Franklin MO Tax Free Income Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4319</td>\n",
       "      <td>Franklin MI Tax-Free Inc Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4364</td>\n",
       "      <td>Franklin Alabama Tax Free Income Advisor</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4328</td>\n",
       "      <td>Franklin Georgia Tax Free Income Advisor</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4327</td>\n",
       "      <td>Franklin CO Tax Free Income Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4370</td>\n",
       "      <td>Franklin NC Tax-Free Income Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4369</td>\n",
       "      <td>Franklin MD Tax Free Income Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4366</td>\n",
       "      <td>Franklin CT Tax-Free Income Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4361</td>\n",
       "      <td>Franklin OR Tax Free Income Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4726</td>\n",
       "      <td>Franklin AZ Tax Free Income Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4368</td>\n",
       "      <td>Franklin Louisiana Tax Free Income Adv</td>\n",
       "      <td>US OE Muni Single State Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4315</td>\n",
       "      <td>Franklin NY Tax Free Income Adv</td>\n",
       "      <td>US OE Muni New York Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4312</td>\n",
       "      <td>Franklin CA Tax Free Income Adv</td>\n",
       "      <td>US OE Muni California Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4152</td>\n",
       "      <td>Franklin CA Interm-Term Tx-Fr Inc Adv</td>\n",
       "      <td>US OE Muni California Intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4153</td>\n",
       "      <td>Franklin NY Intermediate T/F Income Adv</td>\n",
       "      <td>US OE Muni New York Intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4320</td>\n",
       "      <td>Franklin MN Tax-Free Inc Adv</td>\n",
       "      <td>US OE Muni Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4322</td>\n",
       "      <td>Franklin OH Tax-Free Inc Adv</td>\n",
       "      <td>US OE Muni Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4329</td>\n",
       "      <td>Franklin PA Tax-Free Income Adv</td>\n",
       "      <td>US OE Muni Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4318</td>\n",
       "      <td>Franklin MA Tax-Free Income Adv</td>\n",
       "      <td>US OE Muni Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4371</td>\n",
       "      <td>Franklin NJ Tax Free Income Adv</td>\n",
       "      <td>US OE Muni New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>38905</td>\n",
       "      <td>Putnam Tax Exempt Income Y</td>\n",
       "      <td>US OE Muni National Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38914</td>\n",
       "      <td>Putnam Strategic Intermediate Muncpl Y</td>\n",
       "      <td>US OE Muni National Interm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38911</td>\n",
       "      <td>Putnam CA Tax Exempt Income Y</td>\n",
       "      <td>US OE Muni California Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>38912</td>\n",
       "      <td>Putnam NY Tax Exempt Income Y</td>\n",
       "      <td>US OE Muni New York Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38909</td>\n",
       "      <td>Putnam NJ Tax Exempt Income Y</td>\n",
       "      <td>US OE Muni New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>39050</td>\n",
       "      <td>Putnam OH Tax Exempt Income Y</td>\n",
       "      <td>US OE Muni Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>38917</td>\n",
       "      <td>Putnam PA Tax Exempt Income Y</td>\n",
       "      <td>US OE Muni Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>39048</td>\n",
       "      <td>Putnam MA Tax Exempt Income Y</td>\n",
       "      <td>US OE Muni Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39049</td>\n",
       "      <td>Putnam MN Tax Exempt Income Y</td>\n",
       "      <td>US OE Muni Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>38918</td>\n",
       "      <td>Putnam Managed Muni Income</td>\n",
       "      <td>US CE High Yield Muni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>39026</td>\n",
       "      <td>Putnam Municipal Opportunities</td>\n",
       "      <td>US CE Muni National Long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Portfolio_code                          Morningstar_name  \\\n",
       "0             4316      Franklin Federal Tax Free Income Adv   \n",
       "1            26176         Franklin Municipal Green Bond ETF   \n",
       "2             4174  Franklin Federal Interm-Term T/F Inc Adv   \n",
       "3             4363           Franklin VA Tax Free Income Adv   \n",
       "4             4360           Franklin MO Tax Free Income Adv   \n",
       "5             4319              Franklin MI Tax-Free Inc Adv   \n",
       "6             4364  Franklin Alabama Tax Free Income Advisor   \n",
       "7             4328  Franklin Georgia Tax Free Income Advisor   \n",
       "8             4327           Franklin CO Tax Free Income Adv   \n",
       "9             4370           Franklin NC Tax-Free Income Adv   \n",
       "10            4369           Franklin MD Tax Free Income Adv   \n",
       "11            4366           Franklin CT Tax-Free Income Adv   \n",
       "12            4361           Franklin OR Tax Free Income Adv   \n",
       "13            4726           Franklin AZ Tax Free Income Adv   \n",
       "14            4368    Franklin Louisiana Tax Free Income Adv   \n",
       "15            4315           Franklin NY Tax Free Income Adv   \n",
       "16            4312           Franklin CA Tax Free Income Adv   \n",
       "17            4152     Franklin CA Interm-Term Tx-Fr Inc Adv   \n",
       "18            4153   Franklin NY Intermediate T/F Income Adv   \n",
       "19            4320              Franklin MN Tax-Free Inc Adv   \n",
       "20            4322              Franklin OH Tax-Free Inc Adv   \n",
       "21            4329           Franklin PA Tax-Free Income Adv   \n",
       "22            4318           Franklin MA Tax-Free Income Adv   \n",
       "23            4371           Franklin NJ Tax Free Income Adv   \n",
       "24           38905                Putnam Tax Exempt Income Y   \n",
       "25           38914    Putnam Strategic Intermediate Muncpl Y   \n",
       "26           38911             Putnam CA Tax Exempt Income Y   \n",
       "27           38912             Putnam NY Tax Exempt Income Y   \n",
       "28           38909             Putnam NJ Tax Exempt Income Y   \n",
       "29           39050             Putnam OH Tax Exempt Income Y   \n",
       "30           38917             Putnam PA Tax Exempt Income Y   \n",
       "31           39048             Putnam MA Tax Exempt Income Y   \n",
       "32           39049             Putnam MN Tax Exempt Income Y   \n",
       "33           38918                Putnam Managed Muni Income   \n",
       "34           39026            Putnam Municipal Opportunities   \n",
       "\n",
       "                        PeerGroup_name  \n",
       "0             US OE Muni National Long  \n",
       "1             US OE Muni National Long  \n",
       "2           US OE Muni National Interm  \n",
       "3         US OE Muni Single State Long  \n",
       "4         US OE Muni Single State Long  \n",
       "5         US OE Muni Single State Long  \n",
       "6         US OE Muni Single State Long  \n",
       "7         US OE Muni Single State Long  \n",
       "8         US OE Muni Single State Long  \n",
       "9         US OE Muni Single State Long  \n",
       "10        US OE Muni Single State Long  \n",
       "11        US OE Muni Single State Long  \n",
       "12        US OE Muni Single State Long  \n",
       "13        US OE Muni Single State Long  \n",
       "14        US OE Muni Single State Long  \n",
       "15            US OE Muni New York Long  \n",
       "16          US OE Muni California Long  \n",
       "17  US OE Muni California Intermediate  \n",
       "18    US OE Muni New York Intermediate  \n",
       "19                US OE Muni Minnesota  \n",
       "20                     US OE Muni Ohio  \n",
       "21             US OE Muni Pennsylvania  \n",
       "22            US OE Muni Massachusetts  \n",
       "23               US OE Muni New Jersey  \n",
       "24            US OE Muni National Long  \n",
       "25          US OE Muni National Interm  \n",
       "26          US OE Muni California Long  \n",
       "27            US OE Muni New York Long  \n",
       "28               US OE Muni New Jersey  \n",
       "29                     US OE Muni Ohio  \n",
       "30             US OE Muni Pennsylvania  \n",
       "31            US OE Muni Massachusetts  \n",
       "32                US OE Muni Minnesota  \n",
       "33               US CE High Yield Muni  \n",
       "34            US CE Muni National Long  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios\n",
    "peergroups\n",
    "mapping\n",
    "oad_dts\n",
    "curve\n",
    "housing\n",
    "mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9077711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dates & keys\n",
    "portfolios[\"Date\"] = _parse_date(portfolios[\"Date\"])\n",
    "peergroups[\"Date\"] = _parse_date(peergroups[\"Date\"])\n",
    "mapping[\"Portfolio_code\"] = mapping[\"Portfolio_code\"].astype(str).str.strip()\n",
    "\n",
    "# ---------- Standardize Date on Curve & Housing ----------\n",
    "# curve   = ensure_date_column(curve,   preferred=(\"Date\", \"Dates\"))\n",
    "housing = ensure_date_column(housing, preferred=(\"Date\", \"Row Labels\"))\n",
    "\n",
    "# ---------- Filter 1D returns ----------\n",
    "port_ret_1d = (\n",
    "    portfolios\n",
    "    .loc[portfolios[\"Period\"].astype(str).str.upper().eq(\"1D\"), [\"Date\", \"Portfolio\", \"Return\"]]\n",
    "    .rename(columns={\"Return\": \"Portfolio_Return_1D\"})\n",
    "    .dropna(subset=[\"Date\"])\n",
    ")\n",
    "pg_ret_1d = (\n",
    "    peergroups\n",
    "    .loc[peergroups[\"Period\"].astype(str).str.upper().eq(\"1D\"), [\"Date\", \"Portfolio\", \"Median_Return\"]]\n",
    "    .rename(columns={\"Portfolio\": \"PeerGroup_name\", \"Median_Return\": \"PeerGroup_Return_1D\"})\n",
    "    .dropna(subset=[\"Date\"])\n",
    ")\n",
    "\n",
    "# ---------- Housing spreads ----------\n",
    "housing_cols_map = {\n",
    "    \"Multi-Family Private\": \"MF_Private_Spread\",\n",
    "    \"Multi-Family Workforce\": \"MF_Workforce_Spread\",\n",
    "}\n",
    "# tolerate small whitespace/case variations\n",
    "for k in list(housing_cols_map.keys()):\n",
    "    if k not in housing.columns:\n",
    "        for c in housing.columns:\n",
    "            if re.fullmatch(re.sub(r\"\\s+\", r\"\\\\s*\", k), c, flags=re.IGNORECASE):\n",
    "                housing_cols_map[c] = housing_cols_map.pop(k)\n",
    "                break\n",
    "housing_sel = [\"Date\"] + list(housing_cols_map.keys())\n",
    "_require_columns(housing, housing_sel, \"Housing_spreads\")\n",
    "housing_spreads = housing[housing_sel].rename(columns=housing_cols_map).dropna(subset=[\"Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d90829f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\3047280827.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Curve (two-row header): pick 20Y + Spread A/BBB from second header row ----------\n",
    "def _clean(x):\n",
    "    return \"\" if pd.isna(x) else str(x).strip()\n",
    "\n",
    "# Ensure MultiIndex columns are clean strings\n",
    "if not isinstance(curve.columns, pd.MultiIndex):\n",
    "    curve.columns = pd.MultiIndex.from_tuples([(_clean(c), \"\") for c in curve.columns])\n",
    "else:\n",
    "    curve.columns = pd.MultiIndex.from_tuples([(_clean(a), _clean(b)) for a, b in curve.columns])\n",
    "\n",
    "# Detect the Date column by content (either level may say 'Dates')\n",
    "def _score_as_date_col(series, sample_n=200):\n",
    "    s = pd.Series(series).dropna().astype(str)\n",
    "    if sample_n and len(s) > sample_n:\n",
    "        s = s.iloc[:sample_n]\n",
    "    parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
    "    return 0.0 if len(s) == 0 else float(parsed.notna().mean())\n",
    "\n",
    "candidates = []\n",
    "for col in list(curve.columns):\n",
    "    score = _score_as_date_col(curve[col])\n",
    "    a, b = col\n",
    "    if _clean(a).lower() in {\"date\",\"dates\"} or _clean(b).lower() in {\"date\",\"dates\"}:\n",
    "        score += 0.5\n",
    "    candidates.append((score, col))\n",
    "candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "best_score, best_col = candidates[0]\n",
    "if best_score < 0.25:\n",
    "    best_col = curve.columns[0]\n",
    "\n",
    "# Extract Date by position and flatten headers\n",
    "date_idx = list(curve.columns).index(best_col)\n",
    "curve_date = _parse_date(curve.iloc[:, date_idx])\n",
    "curve_flat = curve.copy()\n",
    "curve_flat.columns = [f\"{_clean(a)}::{_clean(b)}\" for (a, b) in curve.columns]\n",
    "curve_flat.insert(0, \"Date\", curve_date)\n",
    "\n",
    "curve_flat = _drop_holidays(curve_flat, \"Date\")\n",
    "\n",
    "# Helper to find the 20Y tenor column from level-0 (numeric 20), else fallback to names\n",
    "def _find_20y_column_from_mi(mi_cols):\n",
    "    # Prefer exact numeric tenor in level-0\n",
    "    for a, b in mi_cols:\n",
    "        try:\n",
    "            if abs(float(a) - 20.0) < 1e-12:\n",
    "                return f\"{_clean(a)}::{_clean(b)}\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Fallback: textual variants in either level\n",
    "    rx = re.compile(r\"(?:^|\\b)20\\s*(?:YR|YEAR|Y)?\\b\", flags=re.IGNORECASE)\n",
    "    for a, b in mi_cols:\n",
    "        if rx.search(_clean(a)) or rx.search(_clean(b)):\n",
    "            return f\"{_clean(a)}::{_clean(b)}\"\n",
    "    raise ValueError(\"[Curve] Could not locate 20Y tenor column.\")\n",
    "\n",
    "# Find Spread A/BBB explicitly from the *second* header row (level-1)\n",
    "def _find_spread_from_second_header(mi_cols, target):\n",
    "    # target is 'Spread A' or 'Spread BBB' (case-insensitive, trim spaces)\n",
    "    for a, b in mi_cols:\n",
    "        if _clean(b).lower() == target.lower():\n",
    "            return f\"{_clean(a)}::{_clean(b)}\"\n",
    "    # light fallback: also accept exact 'A'/'BBB' in second header\n",
    "    short = \"A\" if target.endswith(\"A\") else \"BBB\"\n",
    "    for a, b in mi_cols:\n",
    "        if _clean(b).upper() == short:\n",
    "            return f\"{_clean(a)}::{_clean(b)}\"\n",
    "    return None\n",
    "\n",
    "mi_cols = list(curve.columns)\n",
    "\n",
    "c20_col_flat = _find_20y_column_from_mi(mi_cols)\n",
    "spreadA_flat = _find_spread_from_second_header(mi_cols, \"Spread A\")\n",
    "spreadB_flat = _find_spread_from_second_header(mi_cols, \"Spread BBB\")\n",
    "\n",
    "# Optional fallback to tickers if those names aren't present in row-2\n",
    "if spreadA_flat is None:\n",
    "    for a, b in mi_cols:\n",
    "        if _clean(b) == \"I13971US Index\":\n",
    "            spreadA_flat = f\"{_clean(a)}::{_clean(b)}\"; break\n",
    "if spreadB_flat is None:\n",
    "    for a, b in mi_cols:\n",
    "        if _clean(b) == \"LMB1TR Index\":\n",
    "            spreadB_flat = f\"{_clean(a)}::{_clean(b)}\"; break\n",
    "\n",
    "missing = []\n",
    "if c20_col_flat is None: missing.append(\"20Y tenor\")\n",
    "if spreadA_flat is None: missing.append(\"Spread A (second header)\")\n",
    "if spreadB_flat is None: missing.append(\"Spread BBB (second header)\")\n",
    "if missing:\n",
    "    raise ValueError(f\"[Curve] Missing columns: {', '.join(missing)}\")\n",
    "\n",
    "\n",
    "############################### NEW FOR 4 FACTORS\n",
    "def _find_tenor_from_mi(mi_cols, tenor_target):\n",
    "    # Prefer exact numeric in level-0\n",
    "    for a, b in mi_cols:\n",
    "        try:\n",
    "            if abs(float(str(a).strip()) - float(tenor_target)) < 1e-12:\n",
    "                return f\"{_clean(a)}::{_clean(b)}\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Fallback: textual variants (e.g., \"10Y\", \"30 YEAR\")\n",
    "    rx = re.compile(rf\"(?:^|\\b){int(tenor_target)}\\s*(?:YR|YEAR|Y)?\\b\", flags=re.IGNORECASE)\n",
    "    for a, b in mi_cols:\n",
    "        if rx.search(_clean(a)) or rx.search(_clean(b)):\n",
    "            return f\"{_clean(a)}::{_clean(b)}\"\n",
    "    return None\n",
    "\n",
    "c10_flat = _find_tenor_from_mi(mi_cols, 10.0)\n",
    "c30_flat = _find_tenor_from_mi(mi_cols, 30.0)\n",
    "c12_flat = _find_tenor_from_mi(mi_cols, 12.0)\n",
    "missing = []\n",
    "if c10_flat is None: missing.append(\"10Y tenor\")\n",
    "if c12_flat is None: missing.append(\"12Y tenor\")\n",
    "if c30_flat is None: missing.append(\"30Y tenor\")\n",
    "if missing:\n",
    "    raise ValueError(f\"[Curve] Missing columns: {', '.join(missing)}\")\n",
    "\n",
    "###################################################\n",
    "\n",
    "\n",
    "curve_sel = (\n",
    "    curve_flat.loc[:, [\"Date\", c20_col_flat, c10_flat, c12_flat, c30_flat, spreadA_flat, spreadB_flat]]\n",
    "    .rename(columns={\n",
    "        c20_col_flat: \"CAAA20YR_BVLI\",\n",
    "        c10_flat:     \"Y10\",\n",
    "        c12_flat:     \"CAAA12YR_BVLI\",\n",
    "        c30_flat:     \"Y30\",        \n",
    "        spreadA_flat: \"Spread_A\",\n",
    "        spreadB_flat: \"Spread_BBB\",\n",
    "    })\n",
    "    .dropna(subset=[\"Date\"])\n",
    ")\n",
    "\n",
    "# Daily slope (level), then its daily change\n",
    "curve_sel[\"Slope_30_10\"]  = curve_sel[\"Y30\"] - curve_sel[\"Y10\"]\n",
    "curve_sel[\"d_Slope_30_10\"] = curve_sel[\"Slope_30_10\"].diff()\n",
    "\n",
    "curve_sel[\"d_CAAA12YR_BVLI\"] = curve_sel[\"CAAA12YR_BVLI\"].diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08209ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\2367387881.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_21056\\819496736.py:4: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- OAD/DTS (two-row header flattening + mapping, robust Date extraction) ----------\n",
    "def _clean(x):\n",
    "    return \"\" if pd.isna(x) else str(x).strip()\n",
    "\n",
    "# Ensure columns are a clean MultiIndex (metric in level 0, id/suffix in level 1)\n",
    "if isinstance(oad_dts.columns, pd.MultiIndex):\n",
    "    oad_dts.columns = pd.MultiIndex.from_tuples([(_clean(a), _clean(b)) for a, b in oad_dts.columns])\n",
    "else:\n",
    "    # If reloaded differently, coerce to two levels to keep the rest of logic unified\n",
    "    oad_dts.columns = pd.MultiIndex.from_tuples([(_clean(c), \"\") for c in oad_dts.columns])\n",
    "\n",
    "# --- detect which column is actually the Date column ---\n",
    "def _score_as_date_col(series, sample_n=200):\n",
    "    s = pd.Series(series).dropna().astype(str)\n",
    "    if sample_n and len(s) > sample_n:\n",
    "        s = s.iloc[:sample_n]\n",
    "    parsed = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
    "    return 0.0 if len(s) == 0 else float(parsed.notna().mean())\n",
    "\n",
    "candidates = []\n",
    "for col in list(oad_dts.columns):\n",
    "    score = _score_as_date_col(oad_dts[col])\n",
    "    a, b = col\n",
    "    if _clean(a).lower() == \"date\" or _clean(b).lower() == \"date\":\n",
    "        score += 0.5\n",
    "    candidates.append((score, col))\n",
    "\n",
    "candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "best_score, best_col = candidates[0]\n",
    "# if nothing looks like dates, fall back to the first column\n",
    "if best_score < 0.25:\n",
    "    best_col = oad_dts.columns[0]\n",
    "\n",
    "# --- extract the detected date series by position (avoid label indexing entirely) ---\n",
    "best_idx = list(oad_dts.columns).index(best_col)\n",
    "date_series = _parse_date(oad_dts.iloc[:, best_idx])\n",
    "\n",
    "# --- flatten headers to single level BEFORE we add our own 'Date' column ---\n",
    "flat_cols = [f\"{_clean(a)}::{_clean(b)}\" for (a, b) in oad_dts.columns]\n",
    "oad_dts_flat = oad_dts.copy()\n",
    "oad_dts_flat.columns = flat_cols\n",
    "\n",
    "# Insert a fresh single-level 'Date' column (first position)\n",
    "oad_dts_flat.insert(0, \"Date\", date_series)\n",
    "\n",
    "oad_dts_flat = _drop_holidays(oad_dts_flat, \"Date\")\n",
    "\n",
    "# Build code->column maps from flattened headers\n",
    "oad_map, dts_map = {}, {}\n",
    "for col in oad_dts_flat.columns:\n",
    "    if col == \"Date\":\n",
    "        continue\n",
    "    # expect \"metric::id\"; tolerate missing '::'\n",
    "    parts = col.split(\"::\", 1)\n",
    "    metric = parts[0].lower()\n",
    "    id_part = parts[1] if len(parts) == 2 else \"\"\n",
    "    codes = re.findall(r\"\\d{3,6}\", id_part)\n",
    "    if not codes:\n",
    "        continue\n",
    "    code = codes[-1]  # prefer last if multiple\n",
    "    if \"oad\" in metric:  # e.g., 'Muni_OAD'\n",
    "        oad_map[code] = col\n",
    "    if re.search(r\"\\b(dts|muni[_\\s]*dts)\\b\", metric):\n",
    "        dts_map[code] = col\n",
    "\n",
    "# From here on, use 'oad_dts_flat' instead of 'oad_dts'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10f783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------- per-portfolio build ---------------\n",
    "def build_dataset(row):\n",
    "    \"\"\"\n",
    "    Build one portfolio dataset (last 100 aligned dates).\n",
    "    \"\"\"\n",
    "    code  = str(row[\"Portfolio_code\"]).strip()\n",
    "    pname = str(row[\"Morningstar_name\"]).strip()\n",
    "    gname = str(row[\"PeerGroup_name\"]).strip()\n",
    "\n",
    "    # Portfolio 1D return\n",
    "    p1 = port_ret_1d.loc[port_ret_1d[\"Portfolio\"] == pname, [\"Date\", \"Portfolio_Return_1D\"]]\n",
    "    # Peer group 1D return (median)\n",
    "    p2 = pg_ret_1d.loc[pg_ret_1d[\"PeerGroup_name\"] == gname, [\"Date\", \"PeerGroup_Return_1D\"]]\n",
    "\n",
    "    # OAD / DTS columns via maps\n",
    "    oad_col = _pick_column_for_code(code, oad_map)\n",
    "    dts_col = _pick_column_for_code(code, dts_map)\n",
    "\n",
    "    # Fallback: try regex where both metric and code appear (either order)\n",
    "    if oad_col is None or dts_col is None:\n",
    "        def loose_find(metric_patterns):\n",
    "            code_rx = re.compile(re.escape(code), re.IGNORECASE)\n",
    "            for c in oad_dts_flat.columns:\n",
    "            # for c in oad_dts.columns:\n",
    "                h = str(c)\n",
    "                if c == \"Date\":\n",
    "                    continue\n",
    "                if code_rx.search(h) and metric_patterns.search(h):\n",
    "                    return c\n",
    "                if metric_patterns.search(h) and code_rx.search(h):\n",
    "                    return c\n",
    "            return None\n",
    "        if oad_col is None:\n",
    "            oad_col = loose_find(re.compile(r\"\\bOAD\\b\", re.IGNORECASE))\n",
    "        if dts_col is None:\n",
    "            dts_col = loose_find(re.compile(r\"\\b(DTS|Muni[_\\s]*DTS)\\b\", re.IGNORECASE))\n",
    "\n",
    "    if oad_col is None or dts_col is None:\n",
    "        missing = []\n",
    "        if oad_col is None: missing.append(\"OAD\")\n",
    "        if dts_col is None: missing.append(\"DTS\")\n",
    "        raise KeyError(f\"[OAD_DTS_YTW] Could not find {missing} column(s) for portfolio code {code}\")\n",
    "\n",
    "    p3 = (\n",
    "        oad_dts_flat.loc[:, [\"Date\", oad_col, dts_col]]\n",
    "               .rename(columns={oad_col: \"OAD\", dts_col: \"DTS\"})\n",
    "               .dropna(subset=[\"Date\"])\n",
    "    )\n",
    "\n",
    "    # Global series (same for all portfolios)\n",
    "    p4 = housing_spreads.copy()\n",
    "    p5 = curve_sel.copy()\n",
    "\n",
    "    # Strict alignment: inner joins on Date\n",
    "    dfs = [p1, p2, p3, p4, p5]\n",
    "    dfs_sorted = sorted(dfs, key=lambda d: d.shape[0])\n",
    "    merged = dfs_sorted[0]\n",
    "    for d in dfs_sorted[1:]:\n",
    "        merged = merged.merge(d, on=\"Date\", how=\"inner\")\n",
    "\n",
    "    # Last 100 aligned dates\n",
    "    merged = merged.sort_values(\"Date\").tail(100).reset_index(drop=True)\n",
    "\n",
    "    # Add identity columns\n",
    "    merged.insert(1, \"Portfolio_Name\", pname)\n",
    "    merged.insert(2, \"Portfolio_Code\", code)\n",
    "    merged.insert(3, \"PeerGroup_Name\", gname)\n",
    "\n",
    "    # --- NEW: add daily changes (first differences) for the requested series ---\n",
    "    # We compute X_t = X_t - X_{t-1} on the already date-sorted, aligned data.\n",
    "    # These deltas will be used by the one-factor model (default factor = Spread_A).\n",
    "    change_cols = [\n",
    "        (\"MF_Private_Spread\",   \"d_MF_Private_Spread\"),\n",
    "        (\"MF_Workforce_Spread\", \"d_MF_Workforce_Spread\"),\n",
    "        (\"CAAA20YR_BVLI\",       \"d_CAAA20YR_BVLI\"),\n",
    "        (\"Spread_A\",            \"d_Spread_A\"),\n",
    "        (\"Spread_BBB\",          \"d_Spread_BBB\"),\n",
    "        (\"CAAA12YR_BVLI\",       \"d_CAAA12YR_BVLI\"),\n",
    "    ]\n",
    "    for base, delta in change_cols:\n",
    "        if base in merged.columns:\n",
    "            merged[delta] = merged[base].diff()\n",
    "        else:\n",
    "            merged[delta] = np.nan\n",
    "\n",
    "    # x1 = (-1) * OAD_{t-1} * d_CAAA20YR_BVLI\n",
    "    # x2 = (-1) * DTS_{t-1} * 0.5*(d_Spread_A + d_Spread_BBB)\n",
    "    # x3 = (-1) * 0.5*(d_MF_Private_Spread + d_MF_Workforce_Spread)\n",
    "\n",
    "    merged[\"OAD_lag1\"] = merged[\"OAD\"].shift(1)\n",
    "    merged[\"DTS_lag1\"] = merged[\"DTS\"].shift(1)\n",
    "\n",
    "    merged[\"credit_mix\"] = 0.5 * (merged[\"d_Spread_A\"] + merged[\"d_Spread_BBB\"])\n",
    "    merged[\"mf_mix\"]     = 0.5 * (merged[\"d_MF_Private_Spread\"] + merged[\"d_MF_Workforce_Spread\"])\n",
    "\n",
    "    # merged[\"x1_rate\"]   = - merged[\"OAD_lag1\"] * merged[\"d_CAAA20YR_BVLI\"]\n",
    "    # merged[\"x1_rate12\"]  = - merged[\"OAD_lag1\"] * merged[\"d_CAAA12YR_BVLI\"]\n",
    "    merged[\"x1_rate\"]   = - merged[\"OAD_lag1\"] * merged[\"d_CAAA20YR_BVLI\"]\n",
    "    merged[\"x2_credit\"] = - merged[\"DTS_lag1\"] * merged[\"credit_mix\"]\n",
    "    merged[\"x3_mf\"]     = - merged[\"mf_mix\"]\n",
    "\n",
    "    # --- NEW: robust percent changes for factors (audit-ready) ---\n",
    "    EPS = 1e-6  # small floor to avoid division blowups\n",
    "\n",
    "    def _pct_change(curr, prev, eps=EPS):\n",
    "        denom = np.where(np.abs(prev) < eps, eps, prev)\n",
    "        return (curr - prev) / denom\n",
    "\n",
    "    # Create lagged levels for denominators\n",
    "    merged[\"CAAA20YR_BVLI_lag1\"]       = merged[\"CAAA20YR_BVLI\"].shift(1)\n",
    "    merged[\"Spread_A_lag1\"]            = merged[\"Spread_A\"].shift(1)\n",
    "    merged[\"Spread_BBB_lag1\"]          = merged[\"Spread_BBB\"].shift(1)\n",
    "    merged[\"MF_Private_Spread_lag1\"]   = merged[\"MF_Private_Spread\"].shift(1)\n",
    "    merged[\"MF_Workforce_Spread_lag1\"] = merged[\"MF_Workforce_Spread\"].shift(1)\n",
    "\n",
    "    # Percent changes\n",
    "    merged[\"pc_CAAA20YR_BVLI\"]       = _pct_change(merged[\"CAAA20YR_BVLI\"],       merged[\"CAAA20YR_BVLI_lag1\"])\n",
    "    merged[\"pc_Spread_A\"]            = _pct_change(merged[\"Spread_A\"],            merged[\"Spread_A_lag1\"])\n",
    "    merged[\"pc_Spread_BBB\"]          = _pct_change(merged[\"Spread_BBB\"],          merged[\"Spread_BBB_lag1\"])\n",
    "    merged[\"pc_MF_Private_Spread\"]   = _pct_change(merged[\"MF_Private_Spread\"],   merged[\"MF_Private_Spread_lag1\"])\n",
    "    merged[\"pc_MF_Workforce_Spread\"] = _pct_change(merged[\"MF_Workforce_Spread\"], merged[\"MF_Workforce_Spread_lag1\"])\n",
    "\n",
    "    # Pct-change mixes\n",
    "    merged[\"pc_credit_mix\"] = 0.5 * (merged[\"pc_Spread_A\"] + merged[\"pc_Spread_BBB\"])\n",
    "    merged[\"pc_mf_mix\"]     = 0.5 * (merged[\"pc_MF_Private_Spread\"] + merged[\"pc_MF_Workforce_Spread\"])\n",
    "\n",
    "    # Audited pct-change regressors (parallel to -based ones)\n",
    "    # x1_rate_pct = - OAD_{t-1} * pc_CAAA20YR_BVLI\n",
    "    # x2_credit_pct = - DTS_{t-1} * pc_credit_mix\n",
    "    # x3_mf_pct = - pc_mf_mix\n",
    "    merged[\"x1_rate_pct\"]   = - merged[\"OAD_lag1\"] * merged[\"pc_CAAA20YR_BVLI\"]\n",
    "    merged[\"x2_credit_pct\"] = - merged[\"DTS_lag1\"] * merged[\"pc_credit_mix\"]\n",
    "    merged[\"x3_mf_pct\"]     = - merged[\"pc_mf_mix\"]\n",
    "\n",
    "    # already have: merged includes Y10, Y30, Slope_30_10 from curve_sel merge\n",
    "    # ensure (slope) exists (safe if already computed upstream)\n",
    "    if \"d_Slope_30_10\" not in merged.columns and \"Slope_30_10\" in merged.columns:\n",
    "        merged[\"d_Slope_30_10\"] = merged[\"Slope_30_10\"].diff()\n",
    "\n",
    "    # Factors:\n",
    "    merged[\"x1_rate_mix\"]    = - merged[\"OAD_lag1\"] * merged[\"d_CAAA20YR_BVLI\"]\n",
    "    merged[\"x2_slope_mix\"]   = merged[\"d_Slope_30_10\"]\n",
    "    merged[\"x3_credit_mix\"]  = - merged[\"DTS_lag1\"] * merged[\"pc_credit_mix\"]\n",
    "    merged[\"x4_mf_mix\"]      = - merged[\"pc_mf_mix\"]\n",
    "\n",
    "    # Final column order\n",
    "    final_cols = [\n",
    "        \"Date\",\n",
    "        \"Portfolio_Name\", \"Portfolio_Code\", \"PeerGroup_Name\",\n",
    "        \"Portfolio_Return_1D\", \"PeerGroup_Return_1D\",\n",
    "        \"OAD\", \"DTS\",\n",
    "        \"Y10\", \"Y30\", \"Slope_30_10\", \"d_Slope_30_10\",\n",
    "        \"MF_Private_Spread\", \"d_MF_Private_Spread\",\n",
    "        \"MF_Workforce_Spread\", \"d_MF_Workforce_Spread\",\n",
    "        \"CAAA20YR_BVLI\",\"d_CAAA20YR_BVLI\",\n",
    "        \"CAAA12YR_BVLI\",\"d_CAAA12YR_BVLI\",\n",
    "        \"Spread_A\", \"d_Spread_A\",\n",
    "        \"Spread_BBB\", \"d_Spread_BBB\",\n",
    "        \"x1_rate\",\n",
    "        # \"x1_rate12\",\n",
    "        \"x2_credit\", \"x3_mf\",\n",
    "        \"pc_CAAA20YR_BVLI\", \"pc_Spread_A\", \"pc_Spread_BBB\",\n",
    "        \"pc_MF_Private_Spread\", \"pc_MF_Workforce_Spread\",\n",
    "        \"pc_credit_mix\", \"pc_mf_mix\",\n",
    "        \"x1_rate_pct\", \"x2_credit_pct\", \"x3_mf_pct\",\n",
    "        \"x1_rate_mix\", \"x2_slope_mix\", \"x3_credit_mix\", \"x4_mf_mix\"\n",
    "    ]\n",
    "    merged = merged[final_cols]\n",
    "\n",
    "    # Filename-safe\n",
    "    safe_name = re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", pname).strip(\"_\")\n",
    "    return safe_name, merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f381023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _ols_one_factor(y: pd.Series, x: pd.Series):\n",
    "    \"\"\"\n",
    "    Simple OLS: y = alpha + beta * x + \n",
    "    Returns dict(alpha, beta, r2, t_alpha, t_beta, n)\n",
    "    No external dependencies; uses numpy only.\n",
    "    \"\"\"\n",
    "    # Drop rows with NaNs in either series\n",
    "    df = pd.concat({\"y\": y, \"x\": x}, axis=1).dropna()\n",
    "    n = len(df)\n",
    "    if n < 5:\n",
    "        return {\"alpha\": np.nan, \"beta\": np.nan, \"r2\": np.nan,\n",
    "                \"t_alpha\": np.nan, \"t_beta\": np.nan,\n",
    "                \"p_alpha\": np.nan, \"p_beta\": np.nan, \"n\": n}\n",
    "    \n",
    "    Y = df[\"y\"].to_numpy(dtype=float)\n",
    "    X = df[\"x\"].to_numpy(dtype=float)\n",
    "    # Design matrix with intercept\n",
    "    Xmat = np.column_stack([np.ones(n), X])\n",
    "\n",
    "    # OLS via least squares\n",
    "    coef, residuals, rank, s = np.linalg.lstsq(Xmat, Y, rcond=None)\n",
    "    alpha, beta = coef\n",
    "\n",
    "    # Compute fitted, residuals, R^2\n",
    "    yhat = Xmat @ coef\n",
    "    resid = Y - yhat\n",
    "    ss_res = float(np.sum(resid**2))\n",
    "    ss_tot = float(np.sum((Y - Y.mean())**2))\n",
    "    r2 = 1.0 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
    "\n",
    "    # Robust std errors (homoskedastic OLS)\n",
    "    dof = max(n - 2, 1)\n",
    "    sigma2 = ss_res / dof\n",
    "    XtX_inv = np.linalg.inv(Xmat.T @ Xmat)\n",
    "    se_alpha = np.sqrt(sigma2 * XtX_inv[0, 0])\n",
    "    se_beta  = np.sqrt(sigma2 * XtX_inv[1, 1])\n",
    "\n",
    "    t_alpha = alpha / se_alpha if se_alpha > 0 else np.nan\n",
    "    t_beta  = beta  / se_beta  if se_beta  > 0 else np.nan\n",
    "\n",
    "    # p-values: try exact Student-t; else normal approximation fallback\n",
    "    p_alpha = np.nan\n",
    "    p_beta  = np.nan\n",
    "    try:\n",
    "        from scipy.stats import t as student_t  # optional\n",
    "        if np.isfinite(t_alpha):\n",
    "            p_alpha = 2.0 * student_t.sf(abs(t_alpha), df=dof)\n",
    "        if np.isfinite(t_beta):\n",
    "            p_beta  = 2.0 * student_t.sf(abs(t_beta), df=dof)\n",
    "    except Exception:\n",
    "        # Normal approx: p  2 * (1 - (|t|))\n",
    "        #  via erfc: 1 - (z) = 0.5 * erfc(z / sqrt(2))\n",
    "        def normal_two_sided_p(t):\n",
    "            if not np.isfinite(t):\n",
    "                return np.nan\n",
    "            return 2.0 * 0.5 * math.erfc(abs(t) / math.sqrt(2.0))\n",
    "        p_alpha = normal_two_sided_p(t_alpha)\n",
    "        p_beta  = normal_two_sided_p(t_beta)    \n",
    "\n",
    "    return {\"alpha\": alpha, \"beta\": beta, \"r2\": r2,\n",
    "            \"t_alpha\": t_alpha, \"t_beta\": t_beta,\n",
    "            \"p_alpha\": p_alpha, \"p_beta\": p_beta,\n",
    "            \"n\": n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da257f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ols_multifactor(y: pd.Series, X: np.ndarray, colnames):\n",
    "    \"\"\"\n",
    "    OLS: y = b0 + X @ b + eps\n",
    "    Returns coef, t-stats, p-values, R^2, n.\n",
    "    colnames: list of regressor names matching X columns (for labeling)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    df = pd.concat({\"y\": y}, axis=1).dropna()\n",
    "    # align X to y after the dropna above:\n",
    "    # Build a mask over the original y index to select corresponding X rows\n",
    "    mask = ~pd.isna(y)\n",
    "    # However we already dropped NaNs in a pre-constructed dataframe in the run loop.\n",
    "    # So assume X already matches y length/order there.\n",
    "    n = len(y)\n",
    "    k = X.shape[1] if n > 0 else 0\n",
    "    if n < (k + 5):  # need some dof\n",
    "        res = {\"n\": n, \"r2\": np.nan}\n",
    "        res.update({f\"b{i}\": np.nan for i in range(k+1)})\n",
    "        res.update({f\"t_b{i}\": np.nan for i in range(k+1)})\n",
    "        res.update({f\"p_b{i}\": np.nan for i in range(k+1)})\n",
    "        return res\n",
    "\n",
    "    # Design with intercept\n",
    "    Xmat = np.column_stack([np.ones(n), X])  # n x (k+1)\n",
    "    Y = y.to_numpy(dtype=float)\n",
    "\n",
    "    coef, residuals, rank, s = np.linalg.lstsq(Xmat, Y, rcond=None)\n",
    "    yhat = Xmat @ coef\n",
    "    resid = Y - yhat\n",
    "    ss_res = float(np.sum(resid**2))\n",
    "    ss_tot = float(np.sum((Y - Y.mean())**2))\n",
    "    r2 = 1.0 - ss_res/ss_tot if ss_tot > 0 else np.nan\n",
    "\n",
    "    dof = max(n - (k+1), 1)\n",
    "    sigma2 = ss_res / dof\n",
    "    XtX_inv = np.linalg.inv(Xmat.T @ Xmat)\n",
    "    se = np.sqrt(np.clip(np.diag(XtX_inv) * sigma2, 0, np.inf))  # (k+1,)\n",
    "\n",
    "    tvals = np.where(se > 0, coef / se, np.nan)\n",
    "\n",
    "    # p-values: Student-t if available, else normal approx\n",
    "    pvals = np.full_like(tvals, np.nan, dtype=float)\n",
    "    try:\n",
    "        from scipy.stats import t as student_t\n",
    "        pvals = 2.0 * student_t.sf(np.abs(tvals), df=dof)\n",
    "    except Exception:\n",
    "        pvals = 2.0 * 0.5 * np.vectorize(math.erfc)(np.abs(tvals)/math.sqrt(2.0))\n",
    "\n",
    "    # pack results\n",
    "    out = {\"n\": n, \"r2\": r2}\n",
    "    # b0 then b1..bk\n",
    "    for i in range(k+1):\n",
    "        out[f\"b{i}\"] = coef[i]\n",
    "        out[f\"t_b{i}\"] = tvals[i]\n",
    "        out[f\"p_b{i}\"] = pvals[i]\n",
    "    out[\"_labels\"] = [\"Intercept\"] + list(colnames)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053360d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Built Franklin_Federal_Tax_Free_Income_Adv 4316 (100 rows)\n",
      " Built Franklin_Municipal_Green_Bond_ETF 26176 (100 rows)\n",
      " Built Franklin_Federal_Interm-Term_T_F_Inc_Adv 4174 (100 rows)\n",
      " Built Franklin_VA_Tax_Free_Income_Adv 4363 (100 rows)\n",
      " Built Franklin_MO_Tax_Free_Income_Adv 4360 (100 rows)\n",
      " Built Franklin_MI_Tax-Free_Inc_Adv 4319 (100 rows)\n",
      " Built Franklin_Alabama_Tax_Free_Income_Advisor 4364 (100 rows)\n",
      " Built Franklin_Georgia_Tax_Free_Income_Advisor 4328 (100 rows)\n",
      " Built Franklin_CO_Tax_Free_Income_Adv 4327 (100 rows)\n",
      " Built Franklin_NC_Tax-Free_Income_Adv 4370 (100 rows)\n",
      " Built Franklin_MD_Tax_Free_Income_Adv 4369 (100 rows)\n",
      " Built Franklin_CT_Tax-Free_Income_Adv 4366 (100 rows)\n",
      " Built Franklin_OR_Tax_Free_Income_Adv 4361 (100 rows)\n",
      " Built Franklin_AZ_Tax_Free_Income_Adv 4726 (100 rows)\n",
      " Built Franklin_Louisiana_Tax_Free_Income_Adv 4368 (100 rows)\n",
      " Built Franklin_NY_Tax_Free_Income_Adv 4315 (100 rows)\n",
      " Built Franklin_CA_Tax_Free_Income_Adv 4312 (100 rows)\n",
      " Built Franklin_CA_Interm-Term_Tx-Fr_Inc_Adv 4152 (100 rows)\n",
      " Built Franklin_NY_Intermediate_T_F_Income_Adv 4153 (100 rows)\n",
      " Built Franklin_MN_Tax-Free_Inc_Adv 4320 (100 rows)\n",
      " Built Franklin_OH_Tax-Free_Inc_Adv 4322 (100 rows)\n",
      " Built Franklin_PA_Tax-Free_Income_Adv 4329 (100 rows)\n",
      " Built Franklin_MA_Tax-Free_Income_Adv 4318 (100 rows)\n",
      " Built Franklin_NJ_Tax_Free_Income_Adv 4371 (100 rows)\n",
      " Built Putnam_Tax_Exempt_Income_Y 38905 (100 rows)\n",
      " Built Putnam_Strategic_Intermediate_Muncpl_Y 38914 (100 rows)\n",
      " Built Putnam_CA_Tax_Exempt_Income_Y 38911 (100 rows)\n",
      " Built Putnam_NY_Tax_Exempt_Income_Y 38912 (100 rows)\n",
      " Built Putnam_NJ_Tax_Exempt_Income_Y 38909 (100 rows)\n",
      " Built Putnam_OH_Tax_Exempt_Income_Y 39050 (100 rows)\n",
      " Built Putnam_PA_Tax_Exempt_Income_Y 38917 (100 rows)\n",
      " Built Putnam_MA_Tax_Exempt_Income_Y 39048 (100 rows)\n",
      " Built Putnam_MN_Tax_Exempt_Income_Y 39049 (100 rows)\n",
      " Built Putnam_Managed_Muni_Income 38918 (100 rows)\n",
      " Built Putnam_Municipal_Opportunities 39026 (100 rows)\n",
      "\n",
      "Summary:\n",
      "Datasets built: 35 / 35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------- run for all portfolios and write one Excel ---------------\n",
    "datasets = {}\n",
    "errors = []\n",
    "\n",
    "one_factor_rows = []\n",
    "FACTOR_COLS = [\n",
    "    \"d_CAAA20YR_BVLI\",\n",
    "    \"d_Slope_30_10\",\n",
    "    \"d_Spread_A\",\n",
    "    \"d_Spread_BBB\",\n",
    "    \"d_MF_Private_Spread\",\n",
    "    \"d_MF_Workforce_Spread\",\n",
    "]\n",
    "\n",
    "multi_factor_rows = []\n",
    "\n",
    "\n",
    "for idx, row in mapping.iterrows():\n",
    "    try:\n",
    "        safe_name, dfp = build_dataset(row)\n",
    "        code_key = str(row[\"Portfolio_code\"]).strip()\n",
    "        gname = str(row[\"PeerGroup_name\"]).strip()\n",
    "        datasets[code_key] = dfp\n",
    "\n",
    "        # ---------------- One-factor models ----------------\n",
    "        for fac in FACTOR_COLS:\n",
    "            if fac not in dfp.columns:\n",
    "                one_factor_rows.append({\n",
    "                    \"Portfolio_Code\": code_key,\n",
    "                    \"Portfolio_Name\": safe_name,\n",
    "                    \"Factor\": fac,\n",
    "                    \"alpha\": np.nan, \"beta\": np.nan, \"r2\": np.nan,\n",
    "                    # \"t_alpha\": np.nan, \"t_beta\": np.nan, \"n\": 0\n",
    "                    \"n\": 0\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            df_latest = (\n",
    "                dfp[[\"Date\", \"Portfolio_Return_1D\", fac]]\n",
    "                .dropna()\n",
    "                .sort_values(\"Date\")\n",
    "                .tail(50)\n",
    "            )\n",
    "            y = df_latest[\"Portfolio_Return_1D\"]\n",
    "            x = df_latest[fac]\n",
    "\n",
    "            stats = _ols_one_factor(y, x)\n",
    "            stats[\"n\"] = len(df_latest)\n",
    "\n",
    "            one_factor_rows.append({\n",
    "                \"Portfolio_Code\": code_key,\n",
    "                \"Portfolio_Name\": safe_name,\n",
    "                \"Factor\": fac,\n",
    "                **stats\n",
    "            })\n",
    "\n",
    "        # ---------------- Multi-factor models ----------------\n",
    "        # ---------------- 3-factor spec: x1=rate, x2=credit, x3=MF ----------------\n",
    "        df_reg_port     = dfp[[\"Portfolio_Return_1D\", \"x1_rate\", \"x2_credit\", \"x3_mf\"]].dropna().tail(50)\n",
    "        df_reg_peer     = dfp[[\"PeerGroup_Return_1D\", \"x1_rate\", \"x2_credit\", \"x3_mf\"]].dropna().tail(50)\n",
    "\n",
    "        # Portfolio regression\n",
    "        if len(df_reg_port) >= 8:\n",
    "            y_port = df_reg_port[\"Portfolio_Return_1D\"]\n",
    "            # X_port = df_reg_port[[\"x1\", \"x2\", \"x3\"]].to_numpy(dtype=float)\n",
    "            X_port = df_reg_port[[\"x1_rate\", \"x2_credit\", \"x3_mf\"]].to_numpy(dtype=float)\n",
    "            res_port = _ols_multifactor(y_port, X_port, [\"-OAD*20Y\", \"-DTS*(A+BBB)/2\", \"-MFmix/1\"])\n",
    "        else:\n",
    "            res_port = {k: np.nan for k in [\"b0\",\"b1\",\"t_b1\",\"p_b1\",\"b2\",\"t_b2\",\"p_b2\",\"b3\",\"t_b3\",\"p_b3\",\"r2\",\"n\"]}\n",
    "            res_port[\"n\"] = len(df_reg_port)\n",
    "\n",
    "        # Peer group regression\n",
    "        if len(df_reg_peer) >= 8:\n",
    "            y_peer = df_reg_peer[\"PeerGroup_Return_1D\"]\n",
    "            # X_peer = df_reg_peer[[\"x1\", \"x2\", \"x3\"]].to_numpy(dtype=float)\n",
    "            X_peer = df_reg_peer[[\"x1_rate\", \"x2_credit\", \"x3_mf\"]].to_numpy(dtype=float)\n",
    "            res_peer = _ols_multifactor(y_peer, X_peer, [\"-OAD*20Y\", \"-DTS*(A+BBB)/2\", \"-MFmix/1\"])\n",
    "        else:\n",
    "            res_peer = {k: np.nan for k in [\"b0\",\"b1\",\"t_b1\",\"p_b1\",\"b2\",\"t_b2\",\"p_b2\",\"b3\",\"t_b3\",\"p_b3\",\"r2\",\"n\"]}\n",
    "            res_peer[\"n\"] = len(df_reg_peer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ---------------- 3-factor spec: x1=%rate, x2=%credit, x3=%MF ----------------\n",
    "        df_pct_port = dfp[[\"Portfolio_Return_1D\", \"x1_rate_pct\", \"x2_credit_pct\", \"x3_mf_pct\"]].dropna().tail(50)\n",
    "        df_pct_peer = dfp[[\"PeerGroup_Return_1D\", \"x1_rate_pct\", \"x2_credit_pct\", \"x3_mf_pct\"]].dropna().tail(50)\n",
    "\n",
    "        # Portfolio (pct)\n",
    "        if len(df_pct_port) >= 8:\n",
    "            y_port_pct = df_pct_port[\"Portfolio_Return_1D\"]\n",
    "            X_port_pct = df_pct_port[[\"x1_rate_pct\",\"x2_credit_pct\",\"x3_mf_pct\"]].to_numpy(dtype=float)\n",
    "            res_port_pct = _ols_multifactor(y_port_pct, X_port_pct, [\"-OAD*%20Y\", \"-DTS*%(A+BBB)/2\", \"-%MFmix/1\"])\n",
    "        else:\n",
    "            res_port_pct = {k: np.nan for k in [\"b0\",\"b1\",\"t_b1\",\"p_b1\",\"b2\",\"t_b2\",\"p_b2\",\"b3\",\"t_b3\",\"p_b3\",\"r2\",\"n\"]}\n",
    "            res_port_pct[\"n\"] = len(df_pct_port)\n",
    "\n",
    "        # Peer group (pct)\n",
    "        if len(df_pct_peer) >= 8:\n",
    "            y_peer_pct = df_pct_peer[\"PeerGroup_Return_1D\"]\n",
    "            X_peer_pct = df_pct_peer[[\"x1_rate_pct\",\"x2_credit_pct\",\"x3_mf_pct\"]].to_numpy(dtype=float)\n",
    "            res_peer_pct = _ols_multifactor(y_peer_pct, X_peer_pct, [\"-OAD*%20Y\", \"-DTS*%(A+BBB)/2\", \"-%MFmix/1\"])\n",
    "        else:\n",
    "            res_peer_pct = {k: np.nan for k in [\"b0\",\"b1\",\"t_b1\",\"p_b1\",\"b2\",\"t_b2\",\"p_b2\",\"b3\",\"t_b3\",\"p_b3\",\"r2\",\"n\"]}\n",
    "            res_peer_pct[\"n\"] = len(df_pct_peer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ---------------- 3-factor spec: x1=rate, x2=%credit, x3=%MF ----------------\n",
    "        df_mix_port = dfp[[\"Portfolio_Return_1D\", \"x1_rate\", \"x2_credit_pct\", \"x3_mf_pct\"]].dropna().tail(50)\n",
    "        df_mix_peer = dfp[[\"PeerGroup_Return_1D\", \"x1_rate\", \"x2_credit_pct\", \"x3_mf_pct\"]].dropna().tail(50)\n",
    "\n",
    "        # Portfolio (pct)\n",
    "        if len(df_mix_port) >= 8:\n",
    "            y_port_mix = df_mix_port[\"Portfolio_Return_1D\"]\n",
    "            X_port_mix = df_mix_port[[\"x1_rate\",\"x2_credit_pct\",\"x3_mf_pct\"]].to_numpy(dtype=float)\n",
    "            res_port_mix = _ols_multifactor(y_port_mix, X_port_mix, [\"-OAD*20Y\", \"-DTS*%(A+BBB)/2\", \"-%MFmix/1\"])\n",
    "        else:\n",
    "            res_port_mix = {k: np.nan for k in [\"b0\",\"b1\",\"t_b1\",\"p_b1\",\"b2\",\"t_b2\",\"p_b2\",\"b3\",\"t_b3\",\"p_b3\",\"r2\",\"n\"]}\n",
    "            res_port_mix[\"n\"] = len(df_mix_port)\n",
    "\n",
    "        # Peer group (pct)\n",
    "        if len(df_mix_peer) >= 8:\n",
    "            y_peer_mix = df_mix_peer[\"PeerGroup_Return_1D\"]\n",
    "            X_peer_mix = df_mix_peer[[\"x1_rate\",\"x2_credit_pct\",\"x3_mf_pct\"]].to_numpy(dtype=float)\n",
    "            res_peer_mix = _ols_multifactor(y_peer_mix, X_peer_mix, [\"-OAD*20Y\", \"-DTS*%(A+BBB)/2\", \"-%MFmix/1\"])\n",
    "        else:\n",
    "            res_peer_mix = {k: np.nan for k in [\"b0\",\"b1\",\"t_b1\",\"p_b1\",\"b2\",\"t_b2\",\"p_b2\",\"b3\",\"t_b3\",\"p_b3\",\"r2\",\"n\"]}\n",
    "            res_peer_mix[\"n\"] = len(df_mix_peer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --------------- 4-factor spec: x1=rate, x2=(3010), x3=%credit, x4=%MF ---------------\n",
    "        df4_port = dfp[[\"Portfolio_Return_1D\", \"x1_rate_mix\", \"x2_slope_mix\", \"x3_credit_mix\", \"x4_mf_mix\"]].dropna().tail(50)\n",
    "        df4_peer = dfp[[\"PeerGroup_Return_1D\", \"x1_rate_mix\", \"x2_slope_mix\", \"x3_credit_mix\", \"x4_mf_mix\"]].dropna().tail(50)\n",
    "\n",
    "        if len(df4_port) >= 10:\n",
    "            y4p = df4_port[\"Portfolio_Return_1D\"]\n",
    "            X4p = df4_port[[\"x1_rate_mix\", \"x2_slope_mix\", \"x3_credit_mix\", \"x4_mf_mix\"]].to_numpy(float)\n",
    "            # X4p = df4_port[[\"x1_rate12\",\"x2_slope\",\"x2_credit_pct\",\"x3_mf_pct\"]].to_numpy(float)\n",
    "            # res4_port = _ols_multifactor(y4p, X4p, [\"-OAD*20Y\", \"(30Y-10Y)\", \"-DTS*%(A+BBB)/2\", \"-%MFmix\"])\n",
    "            res4_port = _ols_multifactor(y4p, X4p, [\"-OAD*12Y\", \"(30Y-10Y)\", \"-DTS*%(A+BBB)/2\", \"-%MFmix\"])\n",
    "        else:\n",
    "            res4_port = {k: np.nan for k in [\"b0\",\"b1\",\"b2\",\"b3\",\"b4\",\"r2\",\"n\"]}; res4_port[\"n\"] = len(df4_port)\n",
    "\n",
    "        if len(df4_peer) >= 10:\n",
    "            y4g = df4_peer[\"PeerGroup_Return_1D\"]\n",
    "            X4g = df4_peer[[\"x1_rate_mix\", \"x2_slope_mix\", \"x3_credit_mix\", \"x4_mf_mix\"]].to_numpy(float)\n",
    "            # X4g = df4_peer[[\"x1_rate12\",\"x2_slope\",\"x2_credit_pct\",\"x3_mf_pct\"]].to_numpy(float)\n",
    "            # res4_peer = _ols_multifactor(y4g, X4g, [\"-OAD*20Y\", \"(30Y-10Y)\", \"-DTS*%(A+BBB)/2\", \"-%MFmix\"])\n",
    "            res4_peer = _ols_multifactor(y4g, X4g, [\"-OAD*12Y\", \"(30Y-10Y)\", \"-DTS*%(A+BBB)/2\", \"-%MFmix\"])\n",
    "        else:\n",
    "            res4_peer = {k: np.nan for k in [\"b0\",\"b1\",\"b2\",\"b3\",\"b4\",\"r2\",\"n\"]}; res4_peer[\"n\"] = len(df4_peer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        multi_factor_rows.append({\n",
    "            \"Portfolio_Code\": code_key,\n",
    "            \"Portfolio_Name\": safe_name,\n",
    "            \"PeerGroup_Name\": gname,\n",
    "\n",
    "            # ---------------- 3-factor spec: x1=rate, x2=credit, x3=MF ----------------\n",
    "            # Portfolio regression results\n",
    "            \"b0_po\": res_port.get(\"b0\"),\n",
    "            \"b1_po\": res_port.get(\"b1\"), \"t_po_b1\": res_port.get(\"t_b1\"), \"p_po_b1\": res_port.get(\"p_b1\"),\n",
    "            \"b2_po\": res_port.get(\"b2\"), \"t_po_b2\": res_port.get(\"t_b2\"), \"p_po_b2\": res_port.get(\"p_b2\"),\n",
    "            \"b3_po\": res_port.get(\"b3\"), \"t_po_b3\": res_port.get(\"t_b3\"), \"p_po_b3\": res_port.get(\"p_b3\"),\n",
    "            \"r2_po\": res_port.get(\"r2\"), \"n_po\": res_port.get(\"n\"),\n",
    "\n",
    "            # Peer group regression results\n",
    "            \"b0_pg\": res_peer.get(\"b0\"),\n",
    "            \"b1_pg\": res_peer.get(\"b1\"), \"t_b1_pg\": res_peer.get(\"t_b1\"), \"p_b1_pg\": res_peer.get(\"p_b1\"),\n",
    "            \"b2_pg\": res_peer.get(\"b2\"), \"t_b2_pg\": res_peer.get(\"t_b2\"), \"p_b2_pg\": res_peer.get(\"p_b2\"),\n",
    "            \"b3_pg\": res_peer.get(\"b3\"), \"t_b3_pg\": res_peer.get(\"t_b3\"), \"p_b3_pg\": res_peer.get(\"p_b3\"),\n",
    "            \"r2_pg\": res_peer.get(\"r2\"), \"n_pg\": res_peer.get(\"n\"),\n",
    "\n",
    "\n",
    "\n",
    "            # ---------------- 3-factor spec: x1=%rate, x2=%credit, x3=%MF ----------------\n",
    "            \"b0_po_pct\": res_port_pct.get(\"b0\"),\n",
    "            \"b1_po_pct\": res_port_pct.get(\"b1\"), \"t_b1_po_pct\": res_port_pct.get(\"t_b1\"), \"p_b1_po_pct\": res_port_pct.get(\"p_b1\"),\n",
    "            \"b2_po_pct\": res_port_pct.get(\"b2\"), \"t_b2_po_pct\": res_port_pct.get(\"t_b2\"), \"p_b2_po_pct\": res_port_pct.get(\"p_b2\"),\n",
    "            \"b3_po_pct\": res_port_pct.get(\"b3\"), \"t_b3_po_pct\": res_port_pct.get(\"t_b3\"), \"p_b3_po_pct\": res_port_pct.get(\"p_b3\"),\n",
    "            \"r2_po_pct\": res_port_pct.get(\"r2\"), \"n_po_pct\":   res_port_pct.get(\"n\"),\n",
    "\n",
    "            \"b0_pg_pct\": res_peer_pct.get(\"b0\"),\n",
    "            \"b1_pg_pct\": res_peer_pct.get(\"b1\"), \"t_b1_pg_pct\": res_peer_pct.get(\"t_b1\"), \"p_b1_pg_pct\": res_peer_pct.get(\"p_b1\"),\n",
    "            \"b2_pg_pct\": res_peer_pct.get(\"b2\"), \"t_b2_pg_pct\": res_peer_pct.get(\"t_b2\"), \"p_b2_pg_pct\": res_peer_pct.get(\"p_b2\"),\n",
    "            \"b3_pg_pct\": res_peer_pct.get(\"b3\"), \"t_b3_pg_pct\": res_peer_pct.get(\"t_b3\"), \"p_b3_pg_pct\": res_peer_pct.get(\"p_b3\"),\n",
    "            \"r2_pg_pct\": res_peer_pct.get(\"r2\"), \"n_pg_pct\": res_peer_pct.get(\"n\"),\n",
    "\n",
    "\n",
    "\n",
    "            # ---------------- 3-factor spec: x1=rate, x2=%credit, x3=%MF ----------------\n",
    "            \"b0_po_3f\": res_port_mix.get(\"b0\"),\n",
    "            \"b1_po_3f\": res_port_mix.get(\"b1\"), \"t_b1_po_3f\": res_port_mix.get(\"t_b1\"), \"p_b1_po_3f\": res_port_mix.get(\"p_b1\"),\n",
    "            \"b2_po_3f\": res_port_mix.get(\"b2\"), \"t_b2_po_3f\": res_port_mix.get(\"t_b2\"), \"p_b2_po_3f\": res_port_mix.get(\"p_b2\"),\n",
    "            \"b3_po_3f\": res_port_mix.get(\"b3\"), \"t_b3_po_3f\": res_port_mix.get(\"t_b3\"), \"p_b3_po_3f\": res_port_mix.get(\"p_b3\"),\n",
    "            \"r2_po_3f\": res_port_mix.get(\"r2\"), \"n_po_3f\":   res_port_mix.get(\"n\"),\n",
    "\n",
    "            \"b0_pg_3f\": res_peer_mix.get(\"b0\"),\n",
    "            \"b1_pg_3f\": res_peer_mix.get(\"b1\"), \"t_b1_pg_3f\": res_peer_mix.get(\"t_b1\"), \"p_b1_pg_3f\": res_peer_mix.get(\"p_b1\"),\n",
    "            \"b2_pg_3f\": res_peer_mix.get(\"b2\"), \"t_b2_pg_3f\": res_peer_mix.get(\"t_b2\"), \"p_b2_pg_3f\": res_peer_mix.get(\"p_b2\"),\n",
    "            \"b3_pg_3f\": res_peer_mix.get(\"b3\"), \"t_b3_pg_3f\": res_peer_mix.get(\"t_b3\"), \"p_b3_pg_3f\": res_peer_mix.get(\"p_b3\"),\n",
    "            \"r2_pg_3f\": res_peer_mix.get(\"r2\"), \"n_pg_3f\": res_peer_mix.get(\"n\"),\n",
    "\n",
    "\n",
    "            # --------------- 4-factor spec: x1=rate, x2=(3010), x3=%credit, x4=%MF ---------------\n",
    "            \"b0_po_4f\":   res4_port.get(\"b0\"),\n",
    "            \"b1_po_4f\":   res4_port.get(\"b1\"), \"t_b1_po_4f\": res4_port.get(\"t_b1\"), \"p_b1_po_4f\": res4_port.get(\"p_b1\"),\n",
    "            \"b2_po_4f\":   res4_port.get(\"b2\"), \"t_b2_po_4f\": res4_port.get(\"t_b2\"), \"p_b2_po_4f\": res4_port.get(\"p_b2\"),\n",
    "            \"b3_po_4f\":   res4_port.get(\"b3\"), \"t_b3_po_4f\": res4_port.get(\"t_b3\"), \"p_b3_po_4f\": res4_port.get(\"p_b3\"),\n",
    "            \"b4_po_4f\":   res4_port.get(\"b4\"), \"t_b4_po_4f\": res4_port.get(\"t_b4\"), \"p_b4_po_4f\": res4_port.get(\"p_b4\"),\n",
    "            \"r2_po_4f\":   res4_port.get(\"r2\"), \"n_po_4f\":   res4_port.get(\"n\"),\n",
    "\n",
    "            \"b0_pg_4f\": res4_peer.get(\"b0\"),\n",
    "            \"b1_pg_4f\": res4_peer.get(\"b1\"), \"t_b1_pg_4f\": res4_peer.get(\"t_b1\"), \"p_b1_pg_4f\": res4_peer.get(\"p_b1\"),\n",
    "            \"b2_pg_4f\": res4_peer.get(\"b2\"), \"t_b2_pg_4f\": res4_peer.get(\"t_b2\"), \"p_b2_pg_4f\": res4_peer.get(\"p_b2\"),\n",
    "            \"b3_pg_4f\": res4_peer.get(\"b3\"), \"t_b3_pg_4f\": res4_peer.get(\"t_b3\"), \"p_b3_pg_4f\": res4_peer.get(\"p_b3\"),\n",
    "            \"b4_pg_4f\": res4_peer.get(\"b4\"), \"t_b4_pg_4f\": res4_peer.get(\"t_b4\"), \"p_b4_pg_4f\": res4_peer.get(\"p_b4\"),\n",
    "            \"r2_pg_4f\": res4_peer.get(\"r2\"), \"n_pg_4f\": res4_peer.get(\"n\"),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        })\n",
    "\n",
    "        print(f\" Built {safe_name} {code_key} ({len(dfp)} rows)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append((row.get(\"Morningstar_name\"), str(e)))\n",
    "        print(f\" Failed for {row.get('Morningstar_name')}: {e}\")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Datasets built: {len(datasets)} / {len(mapping)}\")\n",
    "if errors:\n",
    "    print(\"Failures:\")\n",
    "    for name, msg in errors:\n",
    "        print(f\" - {name}: {msg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6aeacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Correlation matrices for Curve/Housing factors (latest 50 aligned dates) --------\n",
    "# Factors: 20Y (CAAA20YR_BVLI), Spread_A, Spread_BBB, MF_Private_Spread, MF_Workforce_Spread\n",
    "\n",
    "# 1) Build a globally aligned factor frame\n",
    "factor_cols_curve   = [\"Date\", \"CAAA20YR_BVLI\", \"Slope_30_10\", \"Spread_A\", \"Spread_BBB\"]\n",
    "factor_cols_housing = [\"Date\", \"MF_Private_Spread\", \"MF_Workforce_Spread\"]\n",
    "\n",
    "factors_all = (\n",
    "    curve_sel[factor_cols_curve]\n",
    "    .merge(housing_spreads[factor_cols_housing], on=\"Date\", how=\"inner\")\n",
    "    .sort_values(\"Date\")\n",
    ")\n",
    "\n",
    "# 2) Restrict to latest 50 aligned dates\n",
    "factors_50 = factors_all.tail(50).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3216fca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>CAAA20YR_BVLI</th>\n",
       "      <th>Slope_30_10</th>\n",
       "      <th>Spread_A</th>\n",
       "      <th>Spread_BBB</th>\n",
       "      <th>MF_Private_Spread</th>\n",
       "      <th>MF_Workforce_Spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2025-10-20</td>\n",
       "      <td>3.8122</td>\n",
       "      <td>1.3160</td>\n",
       "      <td>0.562848</td>\n",
       "      <td>0.897931</td>\n",
       "      <td>2.343517</td>\n",
       "      <td>1.511358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2025-10-21</td>\n",
       "      <td>3.8012</td>\n",
       "      <td>1.3360</td>\n",
       "      <td>0.594061</td>\n",
       "      <td>0.913894</td>\n",
       "      <td>2.347029</td>\n",
       "      <td>1.519070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2025-10-22</td>\n",
       "      <td>3.7802</td>\n",
       "      <td>1.3460</td>\n",
       "      <td>0.611274</td>\n",
       "      <td>0.921223</td>\n",
       "      <td>2.360088</td>\n",
       "      <td>1.527864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2025-10-23</td>\n",
       "      <td>3.7815</td>\n",
       "      <td>1.3430</td>\n",
       "      <td>0.618998</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>2.363703</td>\n",
       "      <td>1.526782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2025-10-24</td>\n",
       "      <td>3.7813</td>\n",
       "      <td>1.3423</td>\n",
       "      <td>0.622011</td>\n",
       "      <td>0.928044</td>\n",
       "      <td>2.364280</td>\n",
       "      <td>1.528018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  CAAA20YR_BVLI  Slope_30_10  Spread_A  Spread_BBB  \\\n",
       "45 2025-10-20         3.8122       1.3160  0.562848    0.897931   \n",
       "46 2025-10-21         3.8012       1.3360  0.594061    0.913894   \n",
       "47 2025-10-22         3.7802       1.3460  0.611274    0.921223   \n",
       "48 2025-10-23         3.7815       1.3430  0.618998    0.922438   \n",
       "49 2025-10-24         3.7813       1.3423  0.622011    0.928044   \n",
       "\n",
       "    MF_Private_Spread  MF_Workforce_Spread  \n",
       "45           2.343517             1.511358  \n",
       "46           2.347029             1.519070  \n",
       "47           2.360088             1.527864  \n",
       "48           2.363703             1.526782  \n",
       "49           2.364280             1.528018  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors_50.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80608abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Correlation on levels (drop Date)\n",
    "corr_levels_50 = factors_50.drop(columns=[\"Date\"]).corr()\n",
    "\n",
    "# 4) Correlation on daily changes (first differences)\n",
    "factors_50_d = factors_50.copy()\n",
    "for c in [\"CAAA20YR_BVLI\", \"Slope_30_10\", \"Spread_A\", \"Spread_BBB\", \"MF_Private_Spread\", \"MF_Workforce_Spread\"]:\n",
    "    factors_50_d[\"d_\" + c] = factors_50_d[c].diff()\n",
    "\n",
    "# Drop the first NaN row after diff\n",
    "corr_deltas_50 = factors_50_d.filter(regex=r\"^d_\").dropna().corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54e88e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAAA20YR_BVLI</th>\n",
       "      <th>Slope_30_10</th>\n",
       "      <th>Spread_A</th>\n",
       "      <th>Spread_BBB</th>\n",
       "      <th>MF_Private_Spread</th>\n",
       "      <th>MF_Workforce_Spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CAAA20YR_BVLI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920254</td>\n",
       "      <td>-0.816868</td>\n",
       "      <td>-0.888395</td>\n",
       "      <td>-0.708313</td>\n",
       "      <td>-0.984978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope_30_10</th>\n",
       "      <td>0.920254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.720453</td>\n",
       "      <td>-0.812139</td>\n",
       "      <td>-0.513998</td>\n",
       "      <td>-0.919770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spread_A</th>\n",
       "      <td>-0.816868</td>\n",
       "      <td>-0.720453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986664</td>\n",
       "      <td>0.315713</td>\n",
       "      <td>0.739360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spread_BBB</th>\n",
       "      <td>-0.888395</td>\n",
       "      <td>-0.812139</td>\n",
       "      <td>0.986664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.402319</td>\n",
       "      <td>0.825345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MF_Private_Spread</th>\n",
       "      <td>-0.708313</td>\n",
       "      <td>-0.513998</td>\n",
       "      <td>0.315713</td>\n",
       "      <td>0.402319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MF_Workforce_Spread</th>\n",
       "      <td>-0.984978</td>\n",
       "      <td>-0.919770</td>\n",
       "      <td>0.739360</td>\n",
       "      <td>0.825345</td>\n",
       "      <td>0.760785</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CAAA20YR_BVLI  Slope_30_10  Spread_A  Spread_BBB  \\\n",
       "CAAA20YR_BVLI             1.000000     0.920254 -0.816868   -0.888395   \n",
       "Slope_30_10               0.920254     1.000000 -0.720453   -0.812139   \n",
       "Spread_A                 -0.816868    -0.720453  1.000000    0.986664   \n",
       "Spread_BBB               -0.888395    -0.812139  0.986664    1.000000   \n",
       "MF_Private_Spread        -0.708313    -0.513998  0.315713    0.402319   \n",
       "MF_Workforce_Spread      -0.984978    -0.919770  0.739360    0.825345   \n",
       "\n",
       "                     MF_Private_Spread  MF_Workforce_Spread  \n",
       "CAAA20YR_BVLI                -0.708313            -0.984978  \n",
       "Slope_30_10                  -0.513998            -0.919770  \n",
       "Spread_A                      0.315713             0.739360  \n",
       "Spread_BBB                    0.402319             0.825345  \n",
       "MF_Private_Spread             1.000000             0.760785  \n",
       "MF_Workforce_Spread           0.760785             1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_levels_50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ccb1bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_CAAA20YR_BVLI</th>\n",
       "      <th>d_Slope_30_10</th>\n",
       "      <th>d_Spread_A</th>\n",
       "      <th>d_Spread_BBB</th>\n",
       "      <th>d_MF_Private_Spread</th>\n",
       "      <th>d_MF_Workforce_Spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d_CAAA20YR_BVLI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379216</td>\n",
       "      <td>-0.380114</td>\n",
       "      <td>-0.527494</td>\n",
       "      <td>-0.542716</td>\n",
       "      <td>-0.602412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_Slope_30_10</th>\n",
       "      <td>0.379216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112006</td>\n",
       "      <td>-0.127749</td>\n",
       "      <td>0.182901</td>\n",
       "      <td>-0.323492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_Spread_A</th>\n",
       "      <td>-0.380114</td>\n",
       "      <td>0.112006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850406</td>\n",
       "      <td>0.174502</td>\n",
       "      <td>0.262248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_Spread_BBB</th>\n",
       "      <td>-0.527494</td>\n",
       "      <td>-0.127749</td>\n",
       "      <td>0.850406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.381223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_MF_Private_Spread</th>\n",
       "      <td>-0.542716</td>\n",
       "      <td>0.182901</td>\n",
       "      <td>0.174502</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_MF_Workforce_Spread</th>\n",
       "      <td>-0.602412</td>\n",
       "      <td>-0.323492</td>\n",
       "      <td>0.262248</td>\n",
       "      <td>0.381223</td>\n",
       "      <td>0.625231</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       d_CAAA20YR_BVLI  d_Slope_30_10  d_Spread_A  \\\n",
       "d_CAAA20YR_BVLI               1.000000       0.379216   -0.380114   \n",
       "d_Slope_30_10                 0.379216       1.000000    0.112006   \n",
       "d_Spread_A                   -0.380114       0.112006    1.000000   \n",
       "d_Spread_BBB                 -0.527494      -0.127749    0.850406   \n",
       "d_MF_Private_Spread          -0.542716       0.182901    0.174502   \n",
       "d_MF_Workforce_Spread        -0.602412      -0.323492    0.262248   \n",
       "\n",
       "                       d_Spread_BBB  d_MF_Private_Spread  \\\n",
       "d_CAAA20YR_BVLI           -0.527494            -0.542716   \n",
       "d_Slope_30_10             -0.127749             0.182901   \n",
       "d_Spread_A                 0.850406             0.174502   \n",
       "d_Spread_BBB               1.000000             0.204300   \n",
       "d_MF_Private_Spread        0.204300             1.000000   \n",
       "d_MF_Workforce_Spread      0.381223             0.625231   \n",
       "\n",
       "                       d_MF_Workforce_Spread  \n",
       "d_CAAA20YR_BVLI                    -0.602412  \n",
       "d_Slope_30_10                      -0.323492  \n",
       "d_Spread_A                          0.262248  \n",
       "d_Spread_BBB                        0.381223  \n",
       "d_MF_Private_Spread                 0.625231  \n",
       "d_MF_Workforce_Spread               1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_deltas_50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c1939a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Correlation of deltas: 20Y, avg(A,BBB), MF_Private, MF_Workforce (latest 50) --------\n",
    "# Build globally aligned factor frame from existing, cleaned tables\n",
    "_factor_cols_curve   = [\"Date\", \"CAAA20YR_BVLI\", \"Slope_30_10\", \"Spread_A\", \"Spread_BBB\"]\n",
    "_factor_cols_housing = [\"Date\", \"MF_Private_Spread\", \"MF_Workforce_Spread\"]\n",
    "\n",
    "_factors_all = (\n",
    "    curve_sel[_factor_cols_curve]\n",
    "    .merge(housing_spreads[_factor_cols_housing], on=\"Date\", how=\"inner\")\n",
    "    .sort_values(\"Date\")\n",
    ")\n",
    "\n",
    "# Compute daily differences (amount changes)\n",
    "_df = _factors_all.copy()\n",
    "_df[\"d_CAAA20YR_BVLI\"]       = _df[\"CAAA20YR_BVLI\"].diff()\n",
    "_df[\"d_Slope_30_10\"]         = _df[\"Slope_30_10\"].diff()\n",
    "_df[\"d_Spread_A\"]            = _df[\"Spread_A\"].diff()\n",
    "_df[\"d_Spread_BBB\"]          = _df[\"Spread_BBB\"].diff()\n",
    "_df[\"d_MF_Private_Spread\"]   = _df[\"MF_Private_Spread\"].diff()\n",
    "_df[\"d_MF_Workforce_Spread\"] = _df[\"MF_Workforce_Spread\"].diff()\n",
    "\n",
    "# Combined IG credit shock: simple average of A & BBB deltas\n",
    "_df[\"d_Spread_A_BBB\"] = 0.5 * (_df[\"d_Spread_A\"] + _df[\"d_Spread_BBB\"])\n",
    "\n",
    "# Keep latest 50 aligned observations with no NaNs across the chosen set\n",
    "_cols_for_corr = [\"d_CAAA20YR_BVLI\", \"d_Slope_30_10\", \"d_Spread_A_BBB\", \"d_MF_Private_Spread\", \"d_MF_Workforce_Spread\"]\n",
    "_df50 = (\n",
    "    _df[[\"Date\"] + _cols_for_corr]\n",
    "    .dropna()\n",
    "    .sort_values(\"Date\")\n",
    "    .tail(50)\n",
    ")\n",
    "\n",
    "corr_deltas_50_igavg = _df50[_cols_for_corr].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd8b7e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_CAAA20YR_BVLI</th>\n",
       "      <th>d_Slope_30_10</th>\n",
       "      <th>d_Spread_A_BBB</th>\n",
       "      <th>d_MF_Private_Spread</th>\n",
       "      <th>d_MF_Workforce_Spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d_CAAA20YR_BVLI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381134</td>\n",
       "      <td>-0.468913</td>\n",
       "      <td>-0.532923</td>\n",
       "      <td>-0.592560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_Slope_30_10</th>\n",
       "      <td>0.381134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003003</td>\n",
       "      <td>0.186414</td>\n",
       "      <td>-0.317366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_Spread_A_BBB</th>\n",
       "      <td>-0.468913</td>\n",
       "      <td>-0.003003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187293</td>\n",
       "      <td>0.320888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_MF_Private_Spread</th>\n",
       "      <td>-0.532923</td>\n",
       "      <td>0.186414</td>\n",
       "      <td>0.187293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_MF_Workforce_Spread</th>\n",
       "      <td>-0.592560</td>\n",
       "      <td>-0.317366</td>\n",
       "      <td>0.320888</td>\n",
       "      <td>0.628443</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       d_CAAA20YR_BVLI  d_Slope_30_10  d_Spread_A_BBB  \\\n",
       "d_CAAA20YR_BVLI               1.000000       0.381134       -0.468913   \n",
       "d_Slope_30_10                 0.381134       1.000000       -0.003003   \n",
       "d_Spread_A_BBB               -0.468913      -0.003003        1.000000   \n",
       "d_MF_Private_Spread          -0.532923       0.186414        0.187293   \n",
       "d_MF_Workforce_Spread        -0.592560      -0.317366        0.320888   \n",
       "\n",
       "                       d_MF_Private_Spread  d_MF_Workforce_Spread  \n",
       "d_CAAA20YR_BVLI                  -0.532923              -0.592560  \n",
       "d_Slope_30_10                     0.186414              -0.317366  \n",
       "d_Spread_A_BBB                    0.187293               0.320888  \n",
       "d_MF_Private_Spread               1.000000               0.628443  \n",
       "d_MF_Workforce_Spread             0.628443               1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_deltas_50_igavg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4365fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if datasets:\n",
    "    excel_path = OUTPUT_DIR / \"all_portfolios_recent50d.xlsx\"\n",
    "    with pd.ExcelWriter(excel_path, engine=\"xlsxwriter\") as writer:\n",
    "        # ---- NEW: sheet names by code ----\n",
    "        for code_key, dfp in datasets.items():\n",
    "            sheet = (code_key[:31])  # Excel sheet name limit is 31\n",
    "            dfp.to_excel(writer, index=False, sheet_name=sheet)\n",
    "\n",
    "        # One-factor summary sheet including Portfolio_Code\n",
    "        if one_factor_rows:\n",
    "            summary_df = pd.DataFrame(one_factor_rows)\n",
    "            summary_df = (\n",
    "                summary_df\n",
    "                .sort_values([\"Factor\", \"Portfolio_Code\"])\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            # ---- NEW: include Portfolio_Code in summary columns ----\n",
    "            col_order = [\"Portfolio_Code\", \"Portfolio_Name\", \"Factor\",\n",
    "                        \"alpha\", \"beta\", \"r2\", \"p_alpha\", \"p_beta\", \"n\"]\n",
    "            summary_df[col_order].to_excel(writer, index=False, sheet_name=\"OneFactor_Summary\")\n",
    "\n",
    "\n",
    "        # ---------------- Multi-factor summary sheet ----------------\n",
    "        if multi_factor_rows:\n",
    "            mf_df = pd.DataFrame(multi_factor_rows)\n",
    "            mf_df = (\n",
    "                mf_df\n",
    "                .sort_values([\"Portfolio_Code\"])\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            col_order = [\"Portfolio_Code\", \"Portfolio_Name\", \"PeerGroup_Name\",\n",
    "                        #  \"b0_po\", \"b1_po\", \"p_b1_po\", \"b2_po\", \"p_b2_po\", \"b3_po\", \"p_b3_po\", \"r2_po\", \"n_po\",\n",
    "                        #  \"b0_pg\", \"b1_pg\", \"p_b1_pg\", \"b2_pg\", \"p_b2_pg\", \"b3_pg\", \"p_b3_pg\", \"r2_pg\", \"n_pg\",\n",
    "                        #  \"b0_po_pct\", \"b1_po_pct\", \"p_b1_po_pct\", \"b2_po_pct\", \"p_b2_po_pct\", \"b3_po_pct\", \"p_b3_po_pct\", \"r2_po_pct\", \"n_po_pct\",\n",
    "                        #  \"b0_pg_pct\", \"b1_pg_pct\", \"p_b1_pg_pct\", \"b2_pg_pct\", \"p_b2_pg_pct\", \"b3_pg_pct\", \"p_b3_pg_pct\", \"r2_pg_pct\", \"n_pg_pct\",\n",
    "                         \"b0_po_3f\", \"b1_po_3f\", \"p_b1_po_3f\", \"b2_po_3f\", \"p_b2_po_3f\", \"b3_po_3f\", \"p_b3_po_3f\", \"r2_po_3f\", \"n_po_3f\",\n",
    "                         \"b0_pg_3f\", \"b1_pg_3f\", \"p_b1_pg_3f\", \"b2_pg_3f\", \"p_b2_pg_3f\", \"b3_pg_3f\", \"p_b3_pg_3f\", \"r2_pg_3f\", \"n_pg_3f\",\n",
    "\n",
    "                         \"b0_po_4f\", \"b1_po_4f\", \"p_b1_po_4f\", \"b2_po_4f\", \"p_b2_po_4f\", \"b3_po_4f\", \"p_b3_po_4f\", \"b4_po_4f\", \"p_b4_po_4f\", \"r2_po_4f\", \"n_po_4f\",\n",
    "                         \"b0_pg_4f\", \"b1_pg_4f\", \"p_b1_pg_4f\", \"b2_pg_4f\", \"p_b2_pg_4f\", \"b3_pg_4f\", \"p_b3_pg_4f\", \"b4_pg_4f\", \"p_b4_pg_4f\", \"r2_pg_4f\", \"n_pg_4f\"\n",
    "                        ]\n",
    "            mf_df[col_order].to_excel(writer, index=False, sheet_name=\"MultiFactor_Summary\")\n",
    "\n",
    "        # corr_deltas_50_igavg.to_excel(writer, sheet_name=\"Corr_Deltas_50_IGavg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0875f83c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
